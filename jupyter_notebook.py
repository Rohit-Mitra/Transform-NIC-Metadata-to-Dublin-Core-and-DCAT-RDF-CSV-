{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIC Metadata to Dublin Core and DCAT Converter\n",
    "This notebook converts metadata from assignment.csv to Dublin Core and DCAT formats.\n",
    "\n",
    "**Output formats:** RDF (Turtle) and CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdflib import Graph, Namespace, Literal, URIRef\n",
    "from rdflib.namespace import RDF, DCTERMS, XSD, FOAF\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Namespaces and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define namespaces\n",
    "DCAT = Namespace(\"http://www.w3.org/ns/dcat#\")\n",
    "DCT = Namespace(\"http://purl.org/dc/terms/\")\n",
    "DATAGOV = Namespace(\"https://data.gov.in\")\n",
    "\n",
    "def normalize_frequency(freq):\n",
    "    \"\"\"Normalize frequency terms to standard vocabulary\"\"\"\n",
    "    freq_mapping = {\n",
    "        'daily': 'http://purl.org/cld/freq/daily',\n",
    "        'weekly': 'http://purl.org/cld/freq/weekly',\n",
    "        'monthly': 'http://purl.org/cld/freq/monthly',\n",
    "        'yearly': 'http://purl.org/cld/freq/annual',\n",
    "        'quarterly': 'http://purl.org/cld/freq/quarterly'\n",
    "    }\n",
    "    if pd.notna(freq):\n",
    "        freq_lower = str(freq).lower().strip()\n",
    "        return freq_mapping.get(freq_lower, freq_lower)\n",
    "    return None\n",
    "\n",
    "def parse_date(date_str):\n",
    "    \"\"\"Parse date string to standard format\"\"\"\n",
    "    if pd.isna(date_str):\n",
    "        return None\n",
    "    try:\n",
    "        for fmt in ['%d/%m/%Y', '%Y-%m-%d', '%m/%d/%Y']:\n",
    "            try:\n",
    "                dt = datetime.strptime(str(date_str), fmt)\n",
    "                return dt.strftime('%Y-%m-%d')\n",
    "            except:\n",
    "                continue\n",
    "        return str(date_str)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_publisher(row):\n",
    "    \"\"\"Get publisher from ministry_department or state_department\"\"\"\n",
    "    if pd.notna(row.get('ministry_department')):\n",
    "        return str(row['ministry_department'])\n",
    "    elif pd.notna(row.get('state_department')):\n",
    "        return str(row['state_department'])\n",
    "    return None\n",
    "\n",
    "def get_description(row):\n",
    "    \"\"\"Get description from catalog_title or note\"\"\"\n",
    "    if pd.notna(row.get('catalog_title')):\n",
    "        desc = str(row['catalog_title'])\n",
    "        if pd.notna(row.get('note')):\n",
    "            desc += \". \" + str(row['note'])\n",
    "        return desc\n",
    "    elif pd.notna(row.get('note')):\n",
    "        return str(row['note'])\n",
    "    return None\n",
    "\n",
    "print(\"Helper functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('assignment.csv')\n",
    "\n",
    "print(f\"Loaded {len(df)} records from assignment.csv\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Dublin Core Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dublin_core_graph(df):\n",
    "    \"\"\"Create RDF graph for Dublin Core metadata\"\"\"\n",
    "    g = Graph()\n",
    "    g.bind(\"dct\", DCT)\n",
    "    g.bind(\"dcterms\", DCTERMS)\n",
    "    \n",
    "    dublin_data = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Create dataset URI\n",
    "        node_alias = row.get('node_alias', '')\n",
    "        if pd.notna(node_alias):\n",
    "            dataset_uri = URIRef(f\"https://data.gov.in{node_alias}\")\n",
    "        else:\n",
    "            dataset_uri = URIRef(f\"https://data.gov.in/dataset/{idx}\")\n",
    "        \n",
    "        # Title\n",
    "        if pd.notna(row.get('title')):\n",
    "            g.add((dataset_uri, DCT.title, Literal(row['title'])))\n",
    "        \n",
    "        # Description\n",
    "        desc = get_description(row)\n",
    "        if desc:\n",
    "            g.add((dataset_uri, DCT.description, Literal(desc)))\n",
    "        \n",
    "        # Issued (published_date)\n",
    "        issued = parse_date(row.get('published_date'))\n",
    "        if issued:\n",
    "            g.add((dataset_uri, DCT.issued, Literal(issued, datatype=XSD.date)))\n",
    "        \n",
    "        # Modified (changed)\n",
    "        modified = parse_date(row.get('changed'))\n",
    "        if modified:\n",
    "            g.add((dataset_uri, DCT.modified, Literal(modified, datatype=XSD.date)))\n",
    "        \n",
    "        # Created\n",
    "        created = parse_date(row.get('created'))\n",
    "        if created:\n",
    "            g.add((dataset_uri, DCT.created, Literal(created, datatype=XSD.date)))\n",
    "        \n",
    "        # Publisher\n",
    "        publisher = get_publisher(row)\n",
    "        if publisher:\n",
    "            g.add((dataset_uri, DCT.publisher, Literal(publisher)))\n",
    "        \n",
    "        # Accrual Periodicity (frequency)\n",
    "        freq = normalize_frequency(row.get('frequency'))\n",
    "        if freq:\n",
    "            if freq.startswith('http'):\n",
    "                g.add((dataset_uri, DCT.accrualPeriodicity, URIRef(freq)))\n",
    "            else:\n",
    "                g.add((dataset_uri, DCT.accrualPeriodicity, Literal(freq)))\n",
    "        \n",
    "        # Subject/Theme (sector)\n",
    "        if pd.notna(row.get('sector')):\n",
    "            sectors = str(row['sector']).split(';')\n",
    "            for sector in sectors:\n",
    "                g.add((dataset_uri, DCT.subject, Literal(sector.strip())))\n",
    "        \n",
    "        # Landing Page\n",
    "        if pd.notna(node_alias):\n",
    "            landing_page = f\"https://data.gov.in{node_alias}\"\n",
    "            g.add((dataset_uri, DCAT.landingPage, URIRef(landing_page)))\n",
    "        \n",
    "        # Collect data for CSV\n",
    "        dublin_data.append({\n",
    "            'dataset_uri': str(dataset_uri),\n",
    "            'title': row.get('title'),\n",
    "            'description': desc,\n",
    "            'issued': issued,\n",
    "            'modified': modified,\n",
    "            'created': created,\n",
    "            'publisher': publisher,\n",
    "            'accrualPeriodicity': freq,\n",
    "            'subject': row.get('sector'),\n",
    "            'landingPage': f\"https://data.gov.in{node_alias}\" if pd.notna(node_alias) else None\n",
    "        })\n",
    "    \n",
    "    return g, pd.DataFrame(dublin_data)\n",
    "\n",
    "# Create Dublin Core metadata\n",
    "print(\"Creating Dublin Core metadata...\")\n",
    "dc_graph, dc_df = create_dublin_core_graph(df)\n",
    "print(f\"✓ Created Dublin Core graph with {len(dc_graph)} triples\")\n",
    "print(f\"✓ Created Dublin Core DataFrame with {len(dc_df)} rows\")\n",
    "\n",
    "# Preview the Dublin Core CSV data\n",
    "print(\"\\nDublin Core CSV Preview:\")\n",
    "dc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create DCAT Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dcat_graph(df):\n",
    "    \"\"\"Create RDF graph for DCAT metadata\"\"\"\n",
    "    g = Graph()\n",
    "    g.bind(\"dcat\", DCAT)\n",
    "    g.bind(\"dct\", DCT)\n",
    "    g.bind(\"dcterms\", DCTERMS)\n",
    "    \n",
    "    dcat_data = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Create dataset URI\n",
    "        node_alias = row.get('node_alias', '')\n",
    "        if pd.notna(node_alias):\n",
    "            dataset_uri = URIRef(f\"https://data.gov.in{node_alias}\")\n",
    "        else:\n",
    "            dataset_uri = URIRef(f\"https://data.gov.in/dataset/{idx}\")\n",
    "        \n",
    "        # Dataset type\n",
    "        g.add((dataset_uri, RDF.type, DCAT.Dataset))\n",
    "        \n",
    "        # Basic metadata (same as Dublin Core)\n",
    "        if pd.notna(row.get('title')):\n",
    "            g.add((dataset_uri, DCT.title, Literal(row['title'])))\n",
    "        \n",
    "        desc = get_description(row)\n",
    "        if desc:\n",
    "            g.add((dataset_uri, DCT.description, Literal(desc)))\n",
    "        \n",
    "        issued = parse_date(row.get('published_date'))\n",
    "        if issued:\n",
    "            g.add((dataset_uri, DCT.issued, Literal(issued, datatype=XSD.date)))\n",
    "        \n",
    "        modified = parse_date(row.get('changed'))\n",
    "        if modified:\n",
    "            g.add((dataset_uri, DCT.modified, Literal(modified, datatype=XSD.date)))\n",
    "        \n",
    "        publisher = get_publisher(row)\n",
    "        if publisher:\n",
    "            g.add((dataset_uri, DCT.publisher, Literal(publisher)))\n",
    "        \n",
    "        freq = normalize_frequency(row.get('frequency'))\n",
    "        if freq:\n",
    "            if freq.startswith('http'):\n",
    "                g.add((dataset_uri, DCT.accrualPeriodicity, URIRef(freq)))\n",
    "            else:\n",
    "                g.add((dataset_uri, DCT.accrualPeriodicity, Literal(freq)))\n",
    "        \n",
    "        if pd.notna(row.get('sector')):\n",
    "            sectors = str(row['sector']).split(';')\n",
    "            for sector in sectors:\n",
    "                g.add((dataset_uri, DCAT.theme, Literal(sector.strip())))\n",
    "        \n",
    "        if pd.notna(node_alias):\n",
    "            landing_page = f\"https://data.gov.in{node_alias}\"\n",
    "            g.add((dataset_uri, DCAT.landingPage, URIRef(landing_page)))\n",
    "        \n",
    "        # Distributions\n",
    "        # API Distribution (datafile_url)\n",
    "        if pd.notna(row.get('datafile_url')):\n",
    "            dist_uri = URIRef(f\"{dataset_uri}/distribution/api\")\n",
    "            g.add((dist_uri, RDF.type, DCAT.Distribution))\n",
    "            g.add((dataset_uri, DCAT.distribution, dist_uri))\n",
    "            g.add((dist_uri, DCAT.accessURL, URIRef(row['datafile_url'])))\n",
    "            \n",
    "            if pd.notna(row.get('file_format')):\n",
    "                g.add((dist_uri, DCT['format'], Literal(row['file_format'])))\n",
    "                g.add((dist_uri, DCAT.mediaType, Literal(row['file_format'])))\n",
    "            \n",
    "            if pd.notna(row.get('file_size')):\n",
    "                try:\n",
    "                    size = int(row['file_size'])\n",
    "                    g.add((dist_uri, DCAT.byteSize, Literal(size, datatype=XSD.integer)))\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            dcat_data.append({\n",
    "                'dataset_uri': str(dataset_uri),\n",
    "                'distribution_uri': str(dist_uri),\n",
    "                'distribution_type': 'API',\n",
    "                'accessURL': row['datafile_url'],\n",
    "                'downloadURL': None,\n",
    "                'format': row.get('file_format'),\n",
    "                'byteSize': row.get('file_size'),\n",
    "                'title': row.get('title')\n",
    "            })\n",
    "        \n",
    "        # File Download Distribution (datafile)\n",
    "        if pd.notna(row.get('datafile')):\n",
    "            dist_uri = URIRef(f\"{dataset_uri}/distribution/file\")\n",
    "            g.add((dist_uri, RDF.type, DCAT.Distribution))\n",
    "            g.add((dataset_uri, DCAT.distribution, dist_uri))\n",
    "            g.add((dist_uri, DCAT.downloadURL, URIRef(row['datafile'])))\n",
    "            \n",
    "            if pd.notna(row.get('file_format')):\n",
    "                g.add((dist_uri, DCT['format'], Literal(row['file_format'])))\n",
    "                g.add((dist_uri, DCAT.mediaType, Literal(row['file_format'])))\n",
    "            \n",
    "            if pd.notna(row.get('file_size')):\n",
    "                try:\n",
    "                    size = int(row['file_size'])\n",
    "                    g.add((dist_uri, DCAT.byteSize, Literal(size, datatype=XSD.integer)))\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            dcat_data.append({\n",
    "                'dataset_uri': str(dataset_uri),\n",
    "                'distribution_uri': str(dist_uri),\n",
    "                'distribution_type': 'File',\n",
    "                'accessURL': None,\n",
    "                'downloadURL': row['datafile'],\n",
    "                'format': row.get('file_format'),\n",
    "                'byteSize': row.get('file_size'),\n",
    "                'title': row.get('title')\n",
    "            })\n",
    "    \n",
    "    return g, pd.DataFrame(dcat_data)\n",
    "\n",
    "# Create DCAT metadata\n",
    "print(\"Creating DCAT metadata...\")\n",
    "dcat_graph, dcat_df = create_dcat_graph(df)\n",
    "print(f\"✓ Created DCAT graph with {len(dcat_graph)} triples\")\n",
    "print(f\"✓ Created DCAT DataFrame with {len(dcat_df)} rows (including distributions)\")\n",
    "\n",
    "# Preview the DCAT CSV data\n",
    "print(\"\\nDCAT CSV Preview:\")\n",
    "dcat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "# Save Dublin Core RDF (Turtle)\n",
    "dc_graph.serialize(destination='output/dublin.ttl', format='turtle')\n",
    "print(\"✓ Created output/dublin.ttl\")\n",
    "\n",
    "# Save Dublin Core CSV\n",
    "dc_df.to_csv('output/dublin.csv', index=False)\n",
    "print(\"✓ Created output/dublin.csv\")\n",
    "\n",
    "# Save DCAT RDF (Turtle)\n",
    "dcat_graph.serialize(destination='output/dcat.ttl', format='turtle')\n",
    "print(\"✓ Created output/dcat.ttl\")\n",
    "\n",
    "# Save DCAT CSV\n",
    "dcat_df.to_csv('output/dcat.csv', index=False)\n",
    "print(\"✓ Created output/dcat.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Conversion completed successfully!\")\n",
    "print(\"Output files created in 'output/' directory\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Preview RDF Output (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few triples from Dublin Core RDF\n",
    "print(\"Dublin Core RDF Sample (first 20 triples):\")\n",
    "print(\"=\"*60)\n",
    "for i, (s, p, o) in enumerate(dc_graph):\n",
    "    if i >= 20:\n",
    "        break\n",
    "    print(f\"{s}\\n  {p}\\n    {o}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few triples from DCAT RDF\n",
    "print(\"DCAT RDF Sample (first 20 triples):\")\n",
    "print(\"=\"*60)\n",
    "for i, (s, p, o) in enumerate(dcat_graph):\n",
    "    if i >= 20:\n",
    "        break\n",
    "    print(f\"{s}\\n  {p}\\n    {o}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
